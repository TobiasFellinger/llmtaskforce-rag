# Results Dashboard

This dashboard is regenerated for every evaluation run

| Model-emb               | Model                 | Date       | Correct (%) | Evaluator Model used | Dataset used    |
|-------------------------|-----------------------|------------|-------|----------|-----------------|
| hkunlp                  | llama3.2:3B           | 2025-01-20 | 43.75 | llama3.2 | ground_truth_v1 |
| hkunlp                  | aycg-llama3.2:3b      | 2025-01-21 | 80.95 | llama3.2 | ground_truth_v1 |
| hkunlp                  | aycg-llama3.2:3b      | 2025-01-27 | 71.79 | llama3.2 | ground_truth_v2 |
| hkunlp                  | aycg-deepseek:1.5b    | 2025-01-28 | 74.36 | llama3.2 | ground_truth_v2 |
| gte-Qwen2-1.5B-instruct | aycg-llama3.2:3b      | 2025-01-28 | 74.36 | llama3.2 | ground_truth_v2 |
| hkunlp                  | aycg-deepseek-r1:1.5b | 2025-01-28 | 84.62 | llama3.2 | ground_truth_v2 |
| hkunlp                  | deepseek-r1:8b        | 2025-01-29 | 94.87 | llama3.2 | ground_truth_v2 |
| hkunlp                  | deepseek-r1:1.5b      | 2025-01-29 | 66.67 | llama3.2 | ground_truth_v2 |
| hkunlp                  | deepseek-r1:1.5b      | 2025-01-29 | 69.23 | llama3.2 | ground_truth_v2 |
| hkunlp                  | deepseek-r1:1.5b      | 2025-01-30 | 79.49 | llama3.2 | ground_truth_v2 |
| hkunlp                  | deepseek-r1:1.5b      | 2025-01-30 | 79.49 | llama3.2 | ground_truth_v2 |
| hkunlp                  | deepseek-r1:8b        | 2025-01-30 | 82.05 | llama3.2 | ground_truth_v2 |
| deepseek-r1:8b | 2025-01-31 | 0.00 | llama3.2:8b |
| deepseek-r1:8b | 2025-01-31 | 0.00 | avcodes/flowaicom-flow-judge:q4 |